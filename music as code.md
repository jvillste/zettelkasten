One hould be able to express a synthesizer as code and show the same as interactive gui. Each function call in the code corresponds to a node in a synth graph in the ui. Adjusting a parmaeter in the ui adds and modifies an argument in a function call in the code.

It should be possible to browse synthesizers and melody generator functions in github by visualizing the synths as modular ui and melodies as pianorolls and then  adding those as dependencies of the current project like code libraries are added for other kinds of programs now.

One should be able to hear a synth function by pointing cursor on it in a code and then adjusting the postiional parameters with knobs.

Music should be published as source code like module files were published in the nineties. One should be able to see how a song is made from note patterns and software synths and samples and modify them. It should be possible to make open source music where all of the synths and samples are availabe on github.

One should be able to record a melody with a midi controller and paste it as code to a unit test and then recreate the meldoy with functions while being able to test wether the functions generate the same melody that was played with the controller.

Music should be composed as functions rather than a sequence of notes like with the traditional staves. Staves do not provide tools for abstarction. A function is the ultimate tool of abstraction.